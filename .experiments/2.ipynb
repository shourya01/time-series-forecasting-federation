{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 23 16:33:18 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:87:00.0 Off |                    0 |\n",
      "| N/A   27C    P0              51W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# infer GPU in use\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# in this notebook, we will analyse the data files and try to see how we can make a custom data loader for the same.\n",
    "\n",
    "data_y_s = np.load('/lcrc/project/NEXTGENOPT/NREL_COMSTOCK_DATA/grouped/G4601010_data.npz')\n",
    "data_x_u = np.load('/lcrc/project/NEXTGENOPT/NREL_COMSTOCK_DATA/grouped/G4601010_weather.npz')\n",
    "\n",
    "# function to calculate model sizes\n",
    "\n",
    "def model_size_in_mb(model):\n",
    "    param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    size_in_mb = param_size / (1024 ** 2)\n",
    "    return f'{size_in_mb:.6f} MB'\n",
    "\n",
    "# function to save model to disk and calculate its size\n",
    "\n",
    "def save_and_measure_model(model):\n",
    "    # Save state_dict\n",
    "    torch.save(model.state_dict(), 'model_state.pth')\n",
    "\n",
    "    # Measure file size\n",
    "    file_size = os.path.getsize('model_state.pth') / (1024 * 1024)\n",
    "\n",
    "    # Delete the file\n",
    "    os.remove('model_state.pth')\n",
    "\n",
    "    return f'{file_size:.6f} MB'\n",
    "    \n",
    "# base data type\n",
    "base_type = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now test out our dataset with california data\n",
    "\n",
    "sys.path.insert(0,'/home/sbose/time-series-forecasting-federation')\n",
    "from models.LFDataset import LFDataset\n",
    "\n",
    "# create dataset\n",
    "CA_dset = LFDataset(\n",
    "    data_y_s = data_y_s,\n",
    "    data_x_u = data_x_u,\n",
    "    lookback = 12,\n",
    "    lookahead = 4,\n",
    "    client_idx = 0,\n",
    "    idx_x = [0,1,2,3,4,5],\n",
    "    idx_u = [6,7],\n",
    "    dtype = base_type\n",
    ")\n",
    "\n",
    "# load into dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "CA_dataloader = DataLoader(CA_dset, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 1th item of dataloader, type of a is <class 'models.LFDataset.TensorList'>, type of b is <class 'models.LFDataset.TensorList'>\n",
      "Shape of 1th item in a is torch.Size([32, 12, 1]).\n",
      "Shape of 2th item in a is torch.Size([32, 12, 6]).\n",
      "Shape of 3th item in a is torch.Size([32, 12, 2]).\n",
      "Shape of 4th item in a is torch.Size([32, 12, 7]).\n",
      "Shape of 5th item in a is torch.Size([32, 4, 2]).\n",
      "Shape of 6th item in a is torch.Size([32, 4, 1]).\n",
      "Shape of 1th item in b is torch.Size([32, 1]).\n",
      "Shape of 2th item in b is torch.Size([32, 4, 1]).\n"
     ]
    }
   ],
   "source": [
    "# Test out the shape of the dataloader outputs\n",
    "\n",
    "for cidx, (a,b) in enumerate(CA_dataloader):\n",
    "    print(f\"On {cidx+1}th item of dataloader, type of a is {type(a)}, type of b is {type(b)}\")\n",
    "    for idx,itm in enumerate(a):\n",
    "        print(f\"Shape of {idx+1}th item in a is {itm.shape}.\")\n",
    "    for idx,itm in enumerate(b):\n",
    "        print(f\"Shape of {idx+1}th item in b is {itm.shape}.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that relative imports from the git repository can always be found\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/home/sbose/time-series-forecasting-federation')\n",
    "\n",
    "# kwargs for all models\n",
    "model_kwargs = {\n",
    "    'x_size': 6,\n",
    "    'y_size': 1,\n",
    "    'u_size': 2,\n",
    "    's_size': 7,\n",
    "    'lookback': 12,\n",
    "    'lookahead': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of LSTM FCNN head output is (32, 1).\n",
      "LSTM FCNN head, torch.float32, theoretical: 0.101093 MB\n",
      "LSTM FCNN head, torch.float32, state_dict on disk: 0.101093 MB\n",
      "LSTM FCNN head, torch.float16, theoretical: 0.050547 MB\n",
      "LSTM FCNN head, torch.float16, state_dict on disk: 0.050547 MB\n",
      "Input dtype is torch.float16.\n",
      "Output dtype is device is torch.float16.\n"
     ]
    }
   ],
   "source": [
    "# test out LSTM vanilla version\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.LSTM.LSTMFCDecoder import LSTMFCDecoder\n",
    "\n",
    "model = LSTMFCDecoder(\n",
    "    **model_kwargs\n",
    ")\n",
    "model_name = 'LSTM FCNN head'\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    w = model(a)\n",
    "    print(f\"Shape of {model_name} output is {tuple(w.shape)}.\")\n",
    "    break\n",
    "\n",
    "# print model size\n",
    "print(f\"{model_name}, {base_type}, theoretical: {model_size_in_mb(model)}\")\n",
    "print(f\"{model_name}, {base_type}, state_dict on disk: {model_size_in_mb(model)}\")\n",
    "\n",
    "# create model of a different dtype\n",
    "dtype, device = torch.float16, 'cuda'\n",
    "model2 = LSTMFCDecoder(\n",
    "    **model_kwargs,\n",
    "    dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "print(f\"{model_name}, {dtype}, theoretical: {model_size_in_mb(model2)}\")\n",
    "print(f\"{model_name}, {dtype}, state_dict on disk: {model_size_in_mb(model2)}\")\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    a,b = a.to(dtype).to(device), b.to(dtype).to(device)\n",
    "    w = model2(a)\n",
    "    print(f\"Input dtype is {dtype}.\")\n",
    "    print(f\"Output dtype is device is {w.dtype}.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of LSTM AR output is (32, 4, 1).\n",
      "LSTM AR, torch.float32, theoretical: 0.045818 MB\n",
      "LSTM AR, torch.float32, state_dict on disk: 0.045818 MB\n",
      "LSTM AR, torch.float16, theoretical: 0.022909 MB\n",
      "LSTM AR, torch.float16, state_dict on disk: 0.022909 MB\n",
      "Input dtype is torch.float16.\n",
      "Output dtype is device is torch.float16.\n"
     ]
    }
   ],
   "source": [
    "# test out LSTM autoregressive version\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.LSTM.LSTMAR import LSTMAR\n",
    "\n",
    "model = LSTMAR(\n",
    "    **model_kwargs\n",
    ")\n",
    "model_name = 'LSTM AR'\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    w = model(a)\n",
    "    print(f\"Shape of {model_name} output is {tuple(w.shape)}.\")\n",
    "    break\n",
    "\n",
    "# print model size\n",
    "print(f\"{model_name}, {base_type}, theoretical: {model_size_in_mb(model)}\")\n",
    "print(f\"{model_name}, {base_type}, state_dict on disk: {model_size_in_mb(model)}\")\n",
    "\n",
    "# create model of a different dtype\n",
    "dtype, device = torch.float16, 'cuda'\n",
    "model2 = LSTMAR(\n",
    "    **model_kwargs,\n",
    "    dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "print(f\"{model_name}, {dtype}, theoretical: {model_size_in_mb(model2)}\")\n",
    "print(f\"{model_name}, {dtype}, state_dict on disk: {model_size_in_mb(model2)}\")\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    a,b = a.to(dtype).to(device), b.to(dtype).to(device)\n",
    "    w = model2(a)\n",
    "    print(f\"Input dtype is {dtype}.\")\n",
    "    print(f\"Output dtype is device is {w.dtype}.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DARNN output is (32, 4, 1).\n",
      "DARNN, torch.float32, theoretical: 0.057205 MB\n",
      "DARNN, torch.float32, state_dict on disk: 0.057205 MB\n",
      "DARNN, torch.float16, theoretical: 0.028603 MB\n",
      "DARNN, torch.float16, state_dict on disk: 0.028603 MB\n",
      "Input dtype is torch.float16.\n",
      "Output dtype is device is torch.float16.\n"
     ]
    }
   ],
   "source": [
    "# test out DARNN\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.DARNN.DARNN import DARNN\n",
    "\n",
    "model = DARNN(\n",
    "    **model_kwargs\n",
    ")\n",
    "model_name = 'DARNN'\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    w = model(a)\n",
    "    print(f\"Shape of {model_name} output is {tuple(w.shape)}.\")\n",
    "    break\n",
    "\n",
    "# print model size\n",
    "print(f\"{model_name}, {base_type}, theoretical: {model_size_in_mb(model)}\")\n",
    "print(f\"{model_name}, {base_type}, state_dict on disk: {model_size_in_mb(model)}\")\n",
    "\n",
    "# create model of a different dtype\n",
    "dtype, device = torch.float16, 'cuda'\n",
    "model2 = DARNN(\n",
    "    **model_kwargs,\n",
    "    dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "print(f\"{model_name}, {dtype}, theoretical: {model_size_in_mb(model2)}\")\n",
    "print(f\"{model_name}, {dtype}, state_dict on disk: {model_size_in_mb(model2)}\")\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    a,b = a.to(dtype).to(device), b.to(dtype).to(device)\n",
    "    w = model2(a)\n",
    "    print(f\"Input dtype is {dtype}.\")\n",
    "    print(f\"Output dtype is device is {w.dtype}.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Transformer AR output is (32, 4, 1).\n",
      "Transformer AR, torch.float32, theoretical: 0.896496 MB\n",
      "Transformer AR, torch.float32, state_dict on disk: 0.896496 MB\n",
      "Transformer AR, torch.float16, theoretical: 0.448248 MB\n",
      "Transformer AR, torch.float16, state_dict on disk: 0.448248 MB\n",
      "Input dtype is torch.float16.\n",
      "Output dtype is device is torch.float16.\n"
     ]
    }
   ],
   "source": [
    "# test out Transformer AR\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.TRANSFORMER.TransformerAR import TransformerAR\n",
    "\n",
    "model = TransformerAR(\n",
    "    **model_kwargs\n",
    ")\n",
    "model_name = 'Transformer AR'\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    w = model(a)\n",
    "    print(f\"Shape of {model_name} output is {tuple(w.shape)}.\")\n",
    "    break\n",
    "\n",
    "# print model size\n",
    "print(f\"{model_name}, {base_type}, theoretical: {model_size_in_mb(model)}\")\n",
    "print(f\"{model_name}, {base_type}, state_dict on disk: {model_size_in_mb(model)}\")\n",
    "\n",
    "# create model of a different dtype\n",
    "dtype, device = torch.float16, 'cuda'\n",
    "model2 = TransformerAR(\n",
    "    **model_kwargs,\n",
    "    dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "print(f\"{model_name}, {dtype}, theoretical: {model_size_in_mb(model2)}\")\n",
    "print(f\"{model_name}, {dtype}, state_dict on disk: {model_size_in_mb(model2)}\")\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    a,b = a.to(dtype).to(device), b.to(dtype).to(device)\n",
    "    w = model2(a)\n",
    "    print(f\"Input dtype is {dtype}.\")\n",
    "    print(f\"Output dtype is device is {w.dtype}.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Transformer output is (32, 4, 1).\n",
      "Transformer, torch.float32, theoretical: 1.419682 MB\n",
      "Transformer, torch.float32, state_dict on disk: 1.419682 MB\n",
      "Transformer, torch.float16, theoretical: 0.448248 MB\n",
      "Transformer, torch.float16, state_dict on disk: 0.448248 MB\n",
      "Input dtype is torch.float16.\n",
      "Output dtype is device is torch.float16.\n"
     ]
    }
   ],
   "source": [
    "# test out Transformer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.TRANSFORMER.Transformer import Transformer\n",
    "\n",
    "model = Transformer(\n",
    "    **model_kwargs\n",
    ")\n",
    "model_name = 'Transformer'\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    w = model(a)\n",
    "    print(f\"Shape of {model_name} output is {tuple(w.shape)}.\")\n",
    "    break\n",
    "\n",
    "# print model size\n",
    "print(f\"{model_name}, {base_type}, theoretical: {model_size_in_mb(model)}\")\n",
    "print(f\"{model_name}, {base_type}, state_dict on disk: {model_size_in_mb(model)}\")\n",
    "\n",
    "# create model of a different dtype\n",
    "dtype, device = torch.float16, 'cuda'\n",
    "model2 = TransformerAR(\n",
    "    **model_kwargs,\n",
    "    dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "print(f\"{model_name}, {dtype}, theoretical: {model_size_in_mb(model2)}\")\n",
    "print(f\"{model_name}, {dtype}, state_dict on disk: {model_size_in_mb(model2)}\")\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    a,b = a.to(dtype).to(device), b.to(dtype).to(device)\n",
    "    w = model2(a)\n",
    "    print(f\"Input dtype is {dtype}.\")\n",
    "    print(f\"Output dtype is device is {w.dtype}.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of LogTrans AR output is (32, 4, 1).\n",
      "LogTrans AR, torch.float32, theoretical: 0.786625 MB\n",
      "LogTrans AR, torch.float32, state_dict on disk: 0.786625 MB\n",
      "LogTrans AR, torch.float16, theoretical: 0.393312 MB\n",
      "LogTrans AR, torch.float16, state_dict on disk: 0.393312 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dtype is torch.float16.\n",
      "Output dtype is device is torch.float16.\n"
     ]
    }
   ],
   "source": [
    "# test out Logtrans\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.LOGTRANS.LogTransAR import LogTransAR\n",
    "model = LogTransAR(\n",
    "    **model_kwargs\n",
    ")\n",
    "model_name = 'LogTrans AR'\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    w = model(a)\n",
    "    print(f\"Shape of {model_name} output is {tuple(w.shape)}.\")\n",
    "    break\n",
    "\n",
    "# print model size\n",
    "print(f\"{model_name}, {base_type}, theoretical: {model_size_in_mb(model)}\")\n",
    "print(f\"{model_name}, {base_type}, state_dict on disk: {model_size_in_mb(model)}\")\n",
    "\n",
    "# create model of a different dtype\n",
    "dtype, device = torch.float16, 'cuda'\n",
    "model2 = LogTransAR(\n",
    "    **model_kwargs,\n",
    "    dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "print(f\"{model_name}, {dtype}, theoretical: {model_size_in_mb(model2)}\")\n",
    "print(f\"{model_name}, {dtype}, state_dict on disk: {model_size_in_mb(model2)}\")\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    a,b = a.to(dtype).to(device), b.to(dtype).to(device)\n",
    "    w = model2(a)\n",
    "    print(f\"Input dtype is {dtype}.\")\n",
    "    print(f\"Output dtype is device is {w.dtype}.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Informer output is (32, 4, 1).\n",
      "Informer, torch.float32, theoretical: 1.467289 MB\n",
      "Informer, torch.float32, state_dict on disk: 1.467289 MB\n",
      "Informer, torch.float16, theoretical: 0.733644 MB\n",
      "Informer, torch.float16, state_dict on disk: 0.733644 MB\n",
      "Input dtype is torch.float16.\n",
      "Output dtype is device is torch.float16.\n"
     ]
    }
   ],
   "source": [
    "# test out Informer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.INFORMER.Informer import Informer\n",
    "model = Informer(\n",
    "    **model_kwargs\n",
    ")\n",
    "model_name = 'Informer'\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    w = model(a)\n",
    "    print(f\"Shape of {model_name} output is {tuple(w.shape)}.\")\n",
    "    break\n",
    "\n",
    "# print model size\n",
    "print(f\"{model_name}, {base_type}, theoretical: {model_size_in_mb(model)}\")\n",
    "print(f\"{model_name}, {base_type}, state_dict on disk: {model_size_in_mb(model)}\")\n",
    "\n",
    "# create model of a different dtype\n",
    "dtype, device = torch.float16, 'cuda'\n",
    "model2 = Informer(\n",
    "    **model_kwargs,\n",
    "    dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "print(f\"{model_name}, {dtype}, theoretical: {model_size_in_mb(model2)}\")\n",
    "print(f\"{model_name}, {dtype}, state_dict on disk: {model_size_in_mb(model2)}\")\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    a,b = a.to(dtype).to(device), b.to(dtype).to(device)\n",
    "    w = model2(a)\n",
    "    print(f\"Input dtype is {dtype}.\")\n",
    "    print(f\"Output dtype is device is {w.dtype}.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Autoformer output is (32, 4, 1).\n",
      "Autoformer, torch.float32, theoretical: 1.407627 MB\n",
      "Autoformer, torch.float32, state_dict on disk: 1.407627 MB\n",
      "NOTICE: Autoformer does not support torch.float16 due to torch.fft.rfft not working with Half for all input tensor shapes.\n",
      "Autoformer, torch.float64, theoretical: 2.815254 MB\n",
      "Autoformer, torch.float64, state_dict on disk: 2.815254 MB\n",
      "Input dtype is torch.float64.\n",
      "Output dtype is device is torch.float64.\n"
     ]
    }
   ],
   "source": [
    "# test out Autoformer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.AUTOFORMER.Autoformer import Autoformer\n",
    "model = Autoformer(\n",
    "    **model_kwargs\n",
    ")\n",
    "model_name = 'Autoformer'\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    w = model(a)\n",
    "    print(f\"Shape of {model_name} output is {tuple(w.shape)}.\")\n",
    "    break\n",
    "\n",
    "# print model size\n",
    "print(f\"{model_name}, {base_type}, theoretical: {model_size_in_mb(model)}\")\n",
    "print(f\"{model_name}, {base_type}, state_dict on disk: {model_size_in_mb(model)}\")\n",
    "\n",
    "# create model of a different dtype\n",
    "dtype, device = torch.float64, 'cuda'\n",
    "print(f\"NOTICE: {model_name} does not support torch.float16 due to torch.fft.rfft not working with Half for all input tensor shapes.\")\n",
    "model2 = Autoformer(\n",
    "    **model_kwargs,\n",
    "    dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "print(f\"{model_name}, {dtype}, theoretical: {model_size_in_mb(model2)}\")\n",
    "print(f\"{model_name}, {dtype}, state_dict on disk: {model_size_in_mb(model2)}\")\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    a,b = a.to(dtype).to(device), b.to(dtype).to(device)\n",
    "    w = model2(a)\n",
    "    print(f\"Input dtype is {dtype}.\")\n",
    "    print(f\"Output dtype is device is {w.dtype}.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out Fedformer Wavelet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.FEDFORMER.FedformerWavelet import FedformerWavelet\n",
    "model = Autoformer(\n",
    "    **model_kwargs\n",
    ")\n",
    "model_name = 'Fedformer Wavelet'\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    w = model(a)\n",
    "    print(f\"Shape of {model_name} output is {tuple(w.shape)}.\")\n",
    "    break\n",
    "\n",
    "# print model size\n",
    "print(f\"{model_name}, {base_type}, theoretical: {model_size_in_mb(model)}\")\n",
    "print(f\"{model_name}, {base_type}, state_dict on disk: {model_size_in_mb(model)}\")\n",
    "\n",
    "# create model of a different dtype\n",
    "dtype, device = torch.float64, 'cuda'\n",
    "print(f\"NOTICE: {model_name} does not support torch.float16 due to torch.fft.rfft not working with Half for all input tensor shapes.\")\n",
    "model2 = FedformerWavelet(\n",
    "    **model_kwargs,\n",
    "    dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "print(f\"{model_name}, {dtype}, theoretical: {model_size_in_mb(model2)}\")\n",
    "print(f\"{model_name}, {dtype}, state_dict on disk: {model_size_in_mb(model2)}\")\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    a,b = a.to(dtype).to(device), b.to(dtype).to(device)\n",
    "    w = model2(a)\n",
    "    print(f\"Input dtype is {dtype}.\")\n",
    "    print(f\"Output dtype is device is {w.dtype}.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Model.__init__() missing 5 required positional arguments: 'dec_in', 'c_out', 'seq_len', 'dec_len', and 'pred_len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 443\u001b[0m\n\u001b[1;32m    440\u001b[0m     wavelet \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    442\u001b[0m configs \u001b[39m=\u001b[39m Configs()\n\u001b[0;32m--> 443\u001b[0m model \u001b[39m=\u001b[39m Model(configs)\n\u001b[1;32m    445\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mparameter number is \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mnumel() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters())))\n\u001b[1;32m    446\u001b[0m enc \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn([\u001b[39m3\u001b[39m, seq_len, \u001b[39m7\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: Model.__init__() missing 5 required positional arguments: 'dec_in', 'c_out', 'seq_len', 'dec_len', and 'pred_len'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "import math\n",
    "from functools import partial\n",
    "from typing import List, Tuple\n",
    "from scipy.special import eval_legendre\n",
    "from sympy import Poly, legendre, Symbol, chebyshevt\n",
    "\n",
    "def legendreDer(k, x):\n",
    "    def _legendre(k, x):\n",
    "        return (2*k+1) * eval_legendre(k, x)\n",
    "    out = 0\n",
    "    for i in np.arange(k-1,-1,-2):\n",
    "        out += _legendre(i, x)\n",
    "    return out\n",
    "\n",
    "\n",
    "def phi_(phi_c, x, lb = 0, ub = 1):\n",
    "    mask = np.logical_or(x<lb, x>ub) * 1.0\n",
    "    return np.polynomial.polynomial.Polynomial(phi_c)(x) * (1-mask)\n",
    "\n",
    "\n",
    "def get_phi_psi(k, base):\n",
    "    \n",
    "    x = Symbol('x')\n",
    "    phi_coeff = np.zeros((k,k))\n",
    "    phi_2x_coeff = np.zeros((k,k))\n",
    "    if base == 'legendre':\n",
    "        for ki in range(k):\n",
    "            coeff_ = Poly(legendre(ki, 2*x-1), x).all_coeffs()\n",
    "            phi_coeff[ki,:ki+1] = np.flip(np.sqrt(2*ki+1) * np.array(coeff_).astype(np.float64))\n",
    "            coeff_ = Poly(legendre(ki, 4*x-1), x).all_coeffs()\n",
    "            phi_2x_coeff[ki,:ki+1] = np.flip(np.sqrt(2) * np.sqrt(2*ki+1) * np.array(coeff_).astype(np.float64))\n",
    "        \n",
    "        psi1_coeff = np.zeros((k, k))\n",
    "        psi2_coeff = np.zeros((k, k))\n",
    "        for ki in range(k):\n",
    "            psi1_coeff[ki,:] = phi_2x_coeff[ki,:]\n",
    "            for i in range(k):\n",
    "                a = phi_2x_coeff[ki,:ki+1]\n",
    "                b = phi_coeff[i, :i+1]\n",
    "                prod_ = np.convolve(a, b)\n",
    "                prod_[np.abs(prod_)<1e-8] = 0\n",
    "                proj_ = (prod_ * 1/(np.arange(len(prod_))+1) * np.power(0.5, 1+np.arange(len(prod_)))).sum()\n",
    "                psi1_coeff[ki,:] -= proj_ * phi_coeff[i,:]\n",
    "                psi2_coeff[ki,:] -= proj_ * phi_coeff[i,:]\n",
    "            for j in range(ki):\n",
    "                a = phi_2x_coeff[ki,:ki+1]\n",
    "                b = psi1_coeff[j, :]\n",
    "                prod_ = np.convolve(a, b)\n",
    "                prod_[np.abs(prod_)<1e-8] = 0\n",
    "                proj_ = (prod_ * 1/(np.arange(len(prod_))+1) * np.power(0.5, 1+np.arange(len(prod_)))).sum()\n",
    "                psi1_coeff[ki,:] -= proj_ * psi1_coeff[j,:]\n",
    "                psi2_coeff[ki,:] -= proj_ * psi2_coeff[j,:]\n",
    "\n",
    "            a = psi1_coeff[ki,:]\n",
    "            prod_ = np.convolve(a, a)\n",
    "            prod_[np.abs(prod_)<1e-8] = 0\n",
    "            norm1 = (prod_ * 1/(np.arange(len(prod_))+1) * np.power(0.5, 1+np.arange(len(prod_)))).sum()\n",
    "\n",
    "            a = psi2_coeff[ki,:]\n",
    "            prod_ = np.convolve(a, a)\n",
    "            prod_[np.abs(prod_)<1e-8] = 0\n",
    "            norm2 = (prod_ * 1/(np.arange(len(prod_))+1) * (1-np.power(0.5, 1+np.arange(len(prod_))))).sum()\n",
    "            norm_ = np.sqrt(norm1 + norm2)\n",
    "            psi1_coeff[ki,:] /= norm_\n",
    "            psi2_coeff[ki,:] /= norm_\n",
    "            psi1_coeff[np.abs(psi1_coeff)<1e-8] = 0\n",
    "            psi2_coeff[np.abs(psi2_coeff)<1e-8] = 0\n",
    "\n",
    "        phi = [np.poly1d(np.flip(phi_coeff[i,:])) for i in range(k)]\n",
    "        psi1 = [np.poly1d(np.flip(psi1_coeff[i,:])) for i in range(k)]\n",
    "        psi2 = [np.poly1d(np.flip(psi2_coeff[i,:])) for i in range(k)]\n",
    "    \n",
    "    elif base == 'chebyshev':\n",
    "        for ki in range(k):\n",
    "            if ki == 0:\n",
    "                phi_coeff[ki,:ki+1] = np.sqrt(2/np.pi)\n",
    "                phi_2x_coeff[ki,:ki+1] = np.sqrt(2/np.pi) * np.sqrt(2)\n",
    "            else:\n",
    "                coeff_ = Poly(chebyshevt(ki, 2*x-1), x).all_coeffs()\n",
    "                phi_coeff[ki,:ki+1] = np.flip(2/np.sqrt(np.pi) * np.array(coeff_).astype(np.float64))\n",
    "                coeff_ = Poly(chebyshevt(ki, 4*x-1), x).all_coeffs()\n",
    "                phi_2x_coeff[ki,:ki+1] = np.flip(np.sqrt(2) * 2 / np.sqrt(np.pi) * np.array(coeff_).astype(np.float64))\n",
    "                \n",
    "        phi = [partial(phi_, phi_coeff[i,:]) for i in range(k)]\n",
    "        \n",
    "        x = Symbol('x')\n",
    "        kUse = 2*k\n",
    "        roots = Poly(chebyshevt(kUse, 2*x-1)).all_roots()\n",
    "        x_m = np.array([rt.evalf(20) for rt in roots]).astype(np.float64)\n",
    "        # x_m[x_m==0.5] = 0.5 + 1e-8 # add small noise to avoid the case of 0.5 belonging to both phi(2x) and phi(2x-1)\n",
    "        # not needed for our purpose here, we use even k always to avoid\n",
    "        wm = np.pi / kUse / 2\n",
    "        \n",
    "        psi1_coeff = np.zeros((k, k))\n",
    "        psi2_coeff = np.zeros((k, k))\n",
    "\n",
    "        psi1 = [[] for _ in range(k)]\n",
    "        psi2 = [[] for _ in range(k)]\n",
    "\n",
    "        for ki in range(k):\n",
    "            psi1_coeff[ki,:] = phi_2x_coeff[ki,:]\n",
    "            for i in range(k):\n",
    "                proj_ = (wm * phi[i](x_m) * np.sqrt(2)* phi[ki](2*x_m)).sum()\n",
    "                psi1_coeff[ki,:] -= proj_ * phi_coeff[i,:]\n",
    "                psi2_coeff[ki,:] -= proj_ * phi_coeff[i,:]\n",
    "\n",
    "            for j in range(ki):\n",
    "                proj_ = (wm * psi1[j](x_m) * np.sqrt(2) * phi[ki](2*x_m)).sum()        \n",
    "                psi1_coeff[ki,:] -= proj_ * psi1_coeff[j,:]\n",
    "                psi2_coeff[ki,:] -= proj_ * psi2_coeff[j,:]\n",
    "\n",
    "            psi1[ki] = partial(phi_, psi1_coeff[ki,:], lb = 0, ub = 0.5)\n",
    "            psi2[ki] = partial(phi_, psi2_coeff[ki,:], lb = 0.5, ub = 1)\n",
    "\n",
    "            norm1 = (wm * psi1[ki](x_m) * psi1[ki](x_m)).sum()\n",
    "            norm2 = (wm * psi2[ki](x_m) * psi2[ki](x_m)).sum()\n",
    "\n",
    "            norm_ = np.sqrt(norm1 + norm2)\n",
    "            psi1_coeff[ki,:] /= norm_\n",
    "            psi2_coeff[ki,:] /= norm_\n",
    "            psi1_coeff[np.abs(psi1_coeff)<1e-8] = 0\n",
    "            psi2_coeff[np.abs(psi2_coeff)<1e-8] = 0\n",
    "\n",
    "            psi1[ki] = partial(phi_, psi1_coeff[ki,:], lb = 0, ub = 0.5+1e-16)\n",
    "            psi2[ki] = partial(phi_, psi2_coeff[ki,:], lb = 0.5+1e-16, ub = 1)\n",
    "        \n",
    "    return phi, psi1, psi2\n",
    "\n",
    "def get_filter(base, k):\n",
    "    \n",
    "    def psi(psi1, psi2, i, inp):\n",
    "        mask = (inp<=0.5) * 1.0\n",
    "        return psi1[i](inp) * mask + psi2[i](inp) * (1-mask)\n",
    "    \n",
    "    if base not in ['legendre', 'chebyshev']:\n",
    "        raise Exception('Base not supported')\n",
    "    \n",
    "    x = Symbol('x')\n",
    "    H0 = np.zeros((k,k))\n",
    "    H1 = np.zeros((k,k))\n",
    "    G0 = np.zeros((k,k))\n",
    "    G1 = np.zeros((k,k))\n",
    "    PHI0 = np.zeros((k,k))\n",
    "    PHI1 = np.zeros((k,k))\n",
    "    phi, psi1, psi2 = get_phi_psi(k, base)\n",
    "    if base == 'legendre':\n",
    "        roots = Poly(legendre(k, 2*x-1)).all_roots()\n",
    "        x_m = np.array([rt.evalf(20) for rt in roots]).astype(np.float64)\n",
    "        wm = 1/k/legendreDer(k,2*x_m-1)/eval_legendre(k-1,2*x_m-1)\n",
    "        \n",
    "        for ki in range(k):\n",
    "            for kpi in range(k):\n",
    "                H0[ki, kpi] = 1/np.sqrt(2) * (wm * phi[ki](x_m/2) * phi[kpi](x_m)).sum()\n",
    "                G0[ki, kpi] = 1/np.sqrt(2) * (wm * psi(psi1, psi2, ki, x_m/2) * phi[kpi](x_m)).sum()\n",
    "                H1[ki, kpi] = 1/np.sqrt(2) * (wm * phi[ki]((x_m+1)/2) * phi[kpi](x_m)).sum()\n",
    "                G1[ki, kpi] = 1/np.sqrt(2) * (wm * psi(psi1, psi2, ki, (x_m+1)/2) * phi[kpi](x_m)).sum()\n",
    "                \n",
    "        PHI0 = np.eye(k)\n",
    "        PHI1 = np.eye(k)\n",
    "                \n",
    "    elif base == 'chebyshev':\n",
    "        x = Symbol('x')\n",
    "        kUse = 2*k\n",
    "        roots = Poly(chebyshevt(kUse, 2*x-1)).all_roots()\n",
    "        x_m = np.array([rt.evalf(20) for rt in roots]).astype(np.float64)\n",
    "        # x_m[x_m==0.5] = 0.5 + 1e-8 # add small noise to avoid the case of 0.5 belonging to both phi(2x) and phi(2x-1)\n",
    "        # not needed for our purpose here, we use even k always to avoid\n",
    "        wm = np.pi / kUse / 2\n",
    "\n",
    "        for ki in range(k):\n",
    "            for kpi in range(k):\n",
    "                H0[ki, kpi] = 1/np.sqrt(2) * (wm * phi[ki](x_m/2) * phi[kpi](x_m)).sum()\n",
    "                G0[ki, kpi] = 1/np.sqrt(2) * (wm * psi(psi1, psi2, ki, x_m/2) * phi[kpi](x_m)).sum()\n",
    "                H1[ki, kpi] = 1/np.sqrt(2) * (wm * phi[ki]((x_m+1)/2) * phi[kpi](x_m)).sum()\n",
    "                G1[ki, kpi] = 1/np.sqrt(2) * (wm * psi(psi1, psi2, ki, (x_m+1)/2) * phi[kpi](x_m)).sum()\n",
    "\n",
    "                PHI0[ki, kpi] = (wm * phi[ki](2*x_m) * phi[kpi](2*x_m)).sum() * 2\n",
    "                PHI1[ki, kpi] = (wm * phi[ki](2*x_m-1) * phi[kpi](2*x_m-1)).sum() * 2\n",
    "                \n",
    "        PHI0[np.abs(PHI0)<1e-8] = 0\n",
    "        PHI1[np.abs(PHI1)<1e-8] = 0\n",
    "\n",
    "    H0[np.abs(H0)<1e-8] = 0\n",
    "    H1[np.abs(H1)<1e-8] = 0\n",
    "    G0[np.abs(G0)<1e-8] = 0\n",
    "    G1[np.abs(G1)<1e-8] = 0\n",
    "        \n",
    "    return H0, H1, G0, G1, PHI0, PHI1\n",
    "\n",
    "class my_Layernorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Special designed layernorm for the seasonal part\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, dtype=torch.float32):\n",
    "        super(my_Layernorm, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(channels, dtype=dtype)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_hat = self.layernorm(x)\n",
    "        bias = torch.mean(x_hat, dim=1).unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "        return x_hat - bias\n",
    "\n",
    "\n",
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, self.kernel_size - 1-math.floor((self.kernel_size - 1) // 2), 1)\n",
    "        end = x[:, -1:, :].repeat(1, math.floor((self.kernel_size - 1) // 2), 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "\n",
    "\n",
    "class series_decomp_multi(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, dtype=torch.float32):\n",
    "        super(series_decomp_multi, self).__init__()\n",
    "        self.moving_avg = [moving_avg(kernel, stride=1) for kernel in kernel_size]\n",
    "        self.layer = torch.nn.Linear(1, len(kernel_size), dtype=dtype)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean=[]\n",
    "        for func in self.moving_avg:\n",
    "            moving_avg = func(x)\n",
    "            moving_mean.append(moving_avg.unsqueeze(-1))\n",
    "        moving_mean=torch.cat(moving_mean,dim=-1)\n",
    "        moving_mean = torch.sum(moving_mean*nn.Softmax(-1)(self.layer(x.unsqueeze(-1))),dim=-1)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean \n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder layer with the progressive decomposition architecture\n",
    "    \"\"\"\n",
    "    def __init__(self, attention, d_model, d_ff=None, moving_avg=25, dropout=0.1, activation=\"relu\", dtype=torch.float32):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False, dtype=dtype)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False, dtype=dtype)\n",
    "\n",
    "        if isinstance(moving_avg, list):\n",
    "            self.decomp1 = series_decomp_multi(moving_avg, dtype=dtype)\n",
    "            self.decomp2 = series_decomp_multi(moving_avg, dtype=dtype)\n",
    "        else:\n",
    "            self.decomp1 = series_decomp(moving_avg)\n",
    "            self.decomp2 = series_decomp(moving_avg)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "        x, _ = self.decomp1(x)\n",
    "        y = x\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "        res, _ = self.decomp2(x + y)\n",
    "        return res, attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer decoder layer with the progressive decomposition architecture\n",
    "    \"\"\"\n",
    "    def __init__(self, self_attention, cross_attention, d_model, c_out, d_ff=None,\n",
    "                 moving_avg=25, dropout=0.1, activation=\"relu\", dtype=torch.float32):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False, dtype=dtype)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False, dtype=dtype)\n",
    "\n",
    "        if isinstance(moving_avg, list):\n",
    "            self.decomp1 = series_decomp_multi(moving_avg, dtype=dtype)\n",
    "            self.decomp2 = series_decomp_multi(moving_avg, dtype=dtype)\n",
    "            self.decomp3 = series_decomp_multi(moving_avg, dtype=dtype)\n",
    "        else:\n",
    "            self.decomp1 = series_decomp(moving_avg)\n",
    "            self.decomp2 = series_decomp(moving_avg)\n",
    "            self.decomp3 = series_decomp(moving_avg)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.projection = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=3, stride=1, padding=1,\n",
    "                                    padding_mode='circular', bias=False, dtype=dtype)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
    "        x = x + self.dropout(self.self_attention(\n",
    "            x, x, x,\n",
    "            attn_mask=x_mask\n",
    "        )[0])\n",
    "\n",
    "        x, trend1 = self.decomp1(x)\n",
    "        x = x + self.dropout(self.cross_attention(\n",
    "            x, cross, cross,\n",
    "            attn_mask=cross_mask\n",
    "        )[0])\n",
    "\n",
    "        x, trend2 = self.decomp2(x)\n",
    "        y = x\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "        x, trend3 = self.decomp3(x + y)\n",
    "\n",
    "        residual_trend = trend1 + trend2 + trend3\n",
    "        residual_trend = self.projection(residual_trend.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x, residual_trend\n",
    "    \n",
    "class AutoCorrelationLayer(nn.Module):\n",
    "    def __init__(self, correlation, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None, dtype=torch.float32):\n",
    "        super(AutoCorrelationLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_correlation = correlation\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads, dtype=dtype)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads, dtype=dtype)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads, dtype=dtype)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model, dtype=dtype)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_correlation(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask\n",
    "        )\n",
    "\n",
    "        out = out.view(B, L, -1)\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layers, norm_layer=None, projection=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, trend=None):\n",
    "        for layer in self.layers:\n",
    "            x, residual_trend = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n",
    "            trend = trend + residual_trend\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        if self.projection is not None:\n",
    "            x = self.projection(x)\n",
    "        return x, trend\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, dtype=torch.float32):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__>='1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, \n",
    "                                    kernel_size=3, padding=padding, padding_mode='circular', dtype=dtype)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)\n",
    "        return x\n",
    "    \n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, dropout=0.1, dtype=torch.float32):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "        self.token_embedding = TokenEmbedding(c_in, d_model, dtype=dtype)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        token_emb = self.token_embedding(x)\n",
    "        return self.dropout(token_emb)\n",
    "    \n",
    "class sparseKernelFT1d(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k, alpha, c=1,\n",
    "                 nl=1,\n",
    "                 initializer=None,\n",
    "                 **kwargs):\n",
    "        super(sparseKernelFT1d, self).__init__()\n",
    "\n",
    "        self.modes1 = alpha\n",
    "        self.scale = (1 / (c * k * c * k))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(c * k, c * k, self.modes1, dtype=torch.cfloat))\n",
    "        self.weights1.requires_grad = True\n",
    "        self.k = k\n",
    "\n",
    "    def compl_mul1d(self, x, weights):\n",
    "        # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n",
    "        return torch.einsum(\"bix,iox->box\", x, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, c, k = x.shape  # (B, N, c, k)\n",
    "\n",
    "        x = x.view(B, N, -1)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x_fft = torch.fft.rfft(x)\n",
    "        # Multiply relevant Fourier modes\n",
    "        l = min(self.modes1, N // 2 + 1)\n",
    "        # l = N//2+1\n",
    "        out_ft = torch.zeros(B, c * k, N // 2 + 1, device=x.device, dtype=torch.cfloat)\n",
    "        out_ft[:, :, :l] = self.compl_mul1d(x_fft[:, :, :l], self.weights1[:, :, :l])\n",
    "        x = torch.fft.irfft(out_ft, n=N)\n",
    "        x = x.permute(0, 2, 1).view(B, N, c, k)\n",
    "        return x\n",
    "    \n",
    "class MWT_CZ1d(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k=3, alpha=64,\n",
    "                 L=0, c=1,\n",
    "                 base='legendre',\n",
    "                 initializer=None,\n",
    "                 **kwargs):\n",
    "        super(MWT_CZ1d, self).__init__()\n",
    "\n",
    "        self.k = k\n",
    "        self.L = L\n",
    "        H0, H1, G0, G1, PHI0, PHI1 = get_filter(base, k)\n",
    "        H0r = H0 @ PHI0\n",
    "        G0r = G0 @ PHI0\n",
    "        H1r = H1 @ PHI1\n",
    "        G1r = G1 @ PHI1\n",
    "\n",
    "        H0r[np.abs(H0r) < 1e-8] = 0\n",
    "        H1r[np.abs(H1r) < 1e-8] = 0\n",
    "        G0r[np.abs(G0r) < 1e-8] = 0\n",
    "        G1r[np.abs(G1r) < 1e-8] = 0\n",
    "        self.max_item = 3\n",
    "\n",
    "        self.A = sparseKernelFT1d(k, alpha, c)\n",
    "        self.B = sparseKernelFT1d(k, alpha, c)\n",
    "        self.C = sparseKernelFT1d(k, alpha, c)\n",
    "\n",
    "        self.T0 = nn.Linear(k, k)\n",
    "\n",
    "        self.register_buffer('ec_s', torch.Tensor(\n",
    "            np.concatenate((H0.T, H1.T), axis=0)))\n",
    "        self.register_buffer('ec_d', torch.Tensor(\n",
    "            np.concatenate((G0.T, G1.T), axis=0)))\n",
    "\n",
    "        self.register_buffer('rc_e', torch.Tensor(\n",
    "            np.concatenate((H0r, G0r), axis=0)))\n",
    "        self.register_buffer('rc_o', torch.Tensor(\n",
    "            np.concatenate((H1r, G1r), axis=0)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, c, k = x.shape  # (B, N, k)\n",
    "        ns = math.floor(np.log2(N))\n",
    "        nl = pow(2, math.ceil(np.log2(N)))\n",
    "        extra_x = x[:, 0:nl - N, :, :]\n",
    "        x = torch.cat([x, extra_x], 1)\n",
    "        Ud = torch.jit.annotate(List[Tensor], [])\n",
    "        Us = torch.jit.annotate(List[Tensor], [])\n",
    "        #         decompose\n",
    "        for i in range(ns - self.L):\n",
    "            # print('x shape',x.shape)\n",
    "            d, x = self.wavelet_transform(x)\n",
    "            Ud += [self.A(d) + self.B(x)]\n",
    "            Us += [self.C(d)]\n",
    "        x = self.T0(x)  # coarsest scale transform\n",
    "\n",
    "        #        reconstruct\n",
    "        for i in range(ns - 1 - self.L, -1, -1):\n",
    "            x = x + Us[i]\n",
    "            x = torch.cat((x, Ud[i]), -1)\n",
    "            x = self.evenOdd(x)\n",
    "        x = x[:, :N, :, :]\n",
    "\n",
    "        return x\n",
    "\n",
    "    def wavelet_transform(self, x):\n",
    "        xa = torch.cat([x[:, ::2, :, :],\n",
    "                        x[:, 1::2, :, :],\n",
    "                        ], -1)\n",
    "        d = torch.matmul(xa, self.ec_d)\n",
    "        s = torch.matmul(xa, self.ec_s)\n",
    "        return d, s\n",
    "\n",
    "    def evenOdd(self, x):\n",
    "\n",
    "        B, N, c, ich = x.shape  # (B, N, c, k)\n",
    "        assert ich == 2 * self.k\n",
    "        x_e = torch.matmul(x, self.rc_e)\n",
    "        x_o = torch.matmul(x, self.rc_o)\n",
    "\n",
    "        x = torch.zeros(B, N * 2, c, self.k,\n",
    "                        device=x.device)\n",
    "        x[..., ::2, :, :] = x_e\n",
    "        x[..., 1::2, :, :] = x_o\n",
    "        return x\n",
    "    \n",
    "class MultiWaveletTransform(nn.Module):\n",
    "    \"\"\"\n",
    "    1D multiwavelet block.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ich=1, k=8, alpha=16, c=128,\n",
    "                 nCZ=1, L=0, base='legendre', attention_dropout=0.1):\n",
    "        super(MultiWaveletTransform, self).__init__()\n",
    "        print('base', base)\n",
    "        self.k = k\n",
    "        self.c = c\n",
    "        self.L = L\n",
    "        self.nCZ = nCZ\n",
    "        self.Lk0 = nn.Linear(ich, c * k)\n",
    "        self.Lk1 = nn.Linear(c * k, ich)\n",
    "        self.ich = ich\n",
    "        self.MWT_CZ = nn.ModuleList(MWT_CZ1d(k, alpha, L, c, base) for i in range(nCZ))\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        if L > S:\n",
    "            zeros = torch.zeros_like(queries[:, :(L - S), :]).float()\n",
    "            values = torch.cat([values, zeros], dim=1)\n",
    "            keys = torch.cat([keys, zeros], dim=1)\n",
    "        else:\n",
    "            values = values[:, :L, :, :]\n",
    "            keys = keys[:, :L, :, :]\n",
    "        values = values.view(B, L, -1)\n",
    "\n",
    "        V = self.Lk0(values).view(B, L, self.c, -1)\n",
    "        for i in range(self.nCZ):\n",
    "            V = self.MWT_CZ[i](V)\n",
    "            if i < self.nCZ - 1:\n",
    "                V = F.relu(V)\n",
    "\n",
    "        V = self.Lk1(V.view(B, L, -1))\n",
    "        V = V.view(B, L, -1, D)\n",
    "        return (V.contiguous(), None)\n",
    "\n",
    "\n",
    "class MultiWaveletCross(nn.Module):\n",
    "    \"\"\"\n",
    "    1D Multiwavelet Cross Attention layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, seq_len_q, seq_len_kv, modes, c=64,\n",
    "                 k=8, ich=512,\n",
    "                 L=0,\n",
    "                 base='legendre',\n",
    "                 mode_select_method='random',\n",
    "                 initializer=None, activation='tanh',\n",
    "                 **kwargs):\n",
    "        super(MultiWaveletCross, self).__init__()\n",
    "        print('base', base)\n",
    "\n",
    "        self.c = c\n",
    "        self.k = k\n",
    "        self.L = L\n",
    "        H0, H1, G0, G1, PHI0, PHI1 = get_filter(base, k)\n",
    "        H0r = H0 @ PHI0\n",
    "        G0r = G0 @ PHI0\n",
    "        H1r = H1 @ PHI1\n",
    "        G1r = G1 @ PHI1\n",
    "\n",
    "        H0r[np.abs(H0r) < 1e-8] = 0\n",
    "        H1r[np.abs(H1r) < 1e-8] = 0\n",
    "        G0r[np.abs(G0r) < 1e-8] = 0\n",
    "        G1r[np.abs(G1r) < 1e-8] = 0\n",
    "        self.max_item = 3\n",
    "\n",
    "        self.attn1 = FourierCrossAttentionW(in_channels=in_channels, out_channels=out_channels, seq_len_q=seq_len_q,\n",
    "                                            seq_len_kv=seq_len_kv, modes=modes, activation=activation,\n",
    "                                            mode_select_method=mode_select_method)\n",
    "        self.attn2 = FourierCrossAttentionW(in_channels=in_channels, out_channels=out_channels, seq_len_q=seq_len_q,\n",
    "                                            seq_len_kv=seq_len_kv, modes=modes, activation=activation,\n",
    "                                            mode_select_method=mode_select_method)\n",
    "        self.attn3 = FourierCrossAttentionW(in_channels=in_channels, out_channels=out_channels, seq_len_q=seq_len_q,\n",
    "                                            seq_len_kv=seq_len_kv, modes=modes, activation=activation,\n",
    "                                            mode_select_method=mode_select_method)\n",
    "        self.attn4 = FourierCrossAttentionW(in_channels=in_channels, out_channels=out_channels, seq_len_q=seq_len_q,\n",
    "                                            seq_len_kv=seq_len_kv, modes=modes, activation=activation,\n",
    "                                            mode_select_method=mode_select_method)\n",
    "        self.T0 = nn.Linear(k, k)\n",
    "        self.register_buffer('ec_s', torch.Tensor(\n",
    "            np.concatenate((H0.T, H1.T), axis=0)))\n",
    "        self.register_buffer('ec_d', torch.Tensor(\n",
    "            np.concatenate((G0.T, G1.T), axis=0)))\n",
    "\n",
    "        self.register_buffer('rc_e', torch.Tensor(\n",
    "            np.concatenate((H0r, G0r), axis=0)))\n",
    "        self.register_buffer('rc_o', torch.Tensor(\n",
    "            np.concatenate((H1r, G1r), axis=0)))\n",
    "\n",
    "        self.Lk = nn.Linear(ich, c * k)\n",
    "        self.Lq = nn.Linear(ich, c * k)\n",
    "        self.Lv = nn.Linear(ich, c * k)\n",
    "        self.out = nn.Linear(c * k, ich)\n",
    "        self.modes1 = modes\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        B, N, H, E = q.shape  # (B, N, H, E) torch.Size([3, 768, 8, 2])\n",
    "        _, S, _, _ = k.shape  # (B, S, H, E) torch.Size([3, 96, 8, 2])\n",
    "\n",
    "        q = q.view(q.shape[0], q.shape[1], -1)\n",
    "        k = k.view(k.shape[0], k.shape[1], -1)\n",
    "        v = v.view(v.shape[0], v.shape[1], -1)\n",
    "        q = self.Lq(q)\n",
    "        q = q.view(q.shape[0], q.shape[1], self.c, self.k)\n",
    "        k = self.Lk(k)\n",
    "        k = k.view(k.shape[0], k.shape[1], self.c, self.k)\n",
    "        v = self.Lv(v)\n",
    "        v = v.view(v.shape[0], v.shape[1], self.c, self.k)\n",
    "\n",
    "        if N > S:\n",
    "            zeros = torch.zeros_like(q[:, :(N - S), :]).float()\n",
    "            v = torch.cat([v, zeros], dim=1)\n",
    "            k = torch.cat([k, zeros], dim=1)\n",
    "        else:\n",
    "            v = v[:, :N, :, :]\n",
    "            k = k[:, :N, :, :]\n",
    "\n",
    "        ns = math.floor(np.log2(N))\n",
    "        nl = pow(2, math.ceil(np.log2(N)))\n",
    "        extra_q = q[:, 0:nl - N, :, :]\n",
    "        extra_k = k[:, 0:nl - N, :, :]\n",
    "        extra_v = v[:, 0:nl - N, :, :]\n",
    "        q = torch.cat([q, extra_q], 1)\n",
    "        k = torch.cat([k, extra_k], 1)\n",
    "        v = torch.cat([v, extra_v], 1)\n",
    "\n",
    "        Ud_q = torch.jit.annotate(List[Tuple[Tensor]], [])\n",
    "        Ud_k = torch.jit.annotate(List[Tuple[Tensor]], [])\n",
    "        Ud_v = torch.jit.annotate(List[Tuple[Tensor]], [])\n",
    "\n",
    "        Us_q = torch.jit.annotate(List[Tensor], [])\n",
    "        Us_k = torch.jit.annotate(List[Tensor], [])\n",
    "        Us_v = torch.jit.annotate(List[Tensor], [])\n",
    "\n",
    "        Ud = torch.jit.annotate(List[Tensor], [])\n",
    "        Us = torch.jit.annotate(List[Tensor], [])\n",
    "\n",
    "        # decompose\n",
    "        for i in range(ns - self.L):\n",
    "            # print('q shape',q.shape)\n",
    "            d, q = self.wavelet_transform(q)\n",
    "            Ud_q += [tuple([d, q])]\n",
    "            Us_q += [d]\n",
    "        for i in range(ns - self.L):\n",
    "            d, k = self.wavelet_transform(k)\n",
    "            Ud_k += [tuple([d, k])]\n",
    "            Us_k += [d]\n",
    "        for i in range(ns - self.L):\n",
    "            d, v = self.wavelet_transform(v)\n",
    "            Ud_v += [tuple([d, v])]\n",
    "            Us_v += [d]\n",
    "        for i in range(ns - self.L):\n",
    "            dk, sk = Ud_k[i], Us_k[i]\n",
    "            dq, sq = Ud_q[i], Us_q[i]\n",
    "            dv, sv = Ud_v[i], Us_v[i]\n",
    "            Ud += [self.attn1(dq[0], dk[0], dv[0], mask)[0] + self.attn2(dq[1], dk[1], dv[1], mask)[0]]\n",
    "            Us += [self.attn3(sq, sk, sv, mask)[0]]\n",
    "        v = self.attn4(q, k, v, mask)[0]\n",
    "\n",
    "        # reconstruct\n",
    "        for i in range(ns - 1 - self.L, -1, -1):\n",
    "            v = v + Us[i]\n",
    "            v = torch.cat((v, Ud[i]), -1)\n",
    "            v = self.evenOdd(v)\n",
    "        v = self.out(v[:, :N, :, :].contiguous().view(B, N, -1))\n",
    "        return (v.contiguous(), None)\n",
    "\n",
    "    def wavelet_transform(self, x):\n",
    "        xa = torch.cat([x[:, ::2, :, :],\n",
    "                        x[:, 1::2, :, :],\n",
    "                        ], -1)\n",
    "        d = torch.matmul(xa, self.ec_d)\n",
    "        s = torch.matmul(xa, self.ec_s)\n",
    "        return d, s\n",
    "\n",
    "    def evenOdd(self, x):\n",
    "        B, N, c, ich = x.shape  # (B, N, c, k)\n",
    "        assert ich == 2 * self.k\n",
    "        x_e = torch.matmul(x, self.rc_e)\n",
    "        x_o = torch.matmul(x, self.rc_o)\n",
    "\n",
    "        x = torch.zeros(B, N * 2, c, self.k,\n",
    "                        device=x.device)\n",
    "        x[..., ::2, :, :] = x_e\n",
    "        x[..., 1::2, :, :] = x_o\n",
    "        return x\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    FEDformer performs the attention mechanism on frequency domain and achieved O(N) complexity\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        enc_in,\n",
    "        dec_in,\n",
    "        c_out,\n",
    "        seq_len,\n",
    "        dec_len,\n",
    "        pred_len,\n",
    "        output_attention = False,\n",
    "        moving_avg = [4,8],\n",
    "        L = 1,\n",
    "        base = 'legendre',\n",
    "        d_model = 64,\n",
    "        modes = 32,\n",
    "        mode_select = 'random',\n",
    "        cross_activation = 'tanh',\n",
    "        n_heads = 4,\n",
    "        d_ff = 512,\n",
    "        d_layers = 2,\n",
    "        e_layers = 2,\n",
    "        activation = 'gelu',\n",
    "        dropout = 0.1,\n",
    "        dtype: torch.dtype = torch.float32\n",
    "    ):\n",
    "        \n",
    "        super(Model, self).__init__()\n",
    "        self.mode_select = mode_select\n",
    "        self.modes = modes\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = dec_len\n",
    "        self.pred_len = pred_len\n",
    "        self.output_attention = output_attention\n",
    "        self.dtype = dtype\n",
    "\n",
    "        # Decomp\n",
    "        kernel_size = moving_avg\n",
    "        if isinstance(kernel_size, list):\n",
    "            self.decomp = series_decomp_multi(kernel_size, dtype=dtype)\n",
    "        else:\n",
    "            self.decomp = series_decomp(kernel_size)\n",
    "\n",
    "        # Embedding\n",
    "        # The series-wise connection inherently contains the sequential information.\n",
    "        # Thus, we can discard the position embedding of transformers.\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, dropout=dropout, dtype=dtype)\n",
    "        self.dec_embedding = DataEmbedding(dec_in, d_model, dropout=dropout, dtype=dtype)\n",
    "\n",
    "        encoder_self_att = MultiWaveletTransform(ich=d_model, L=L, base=base)\n",
    "        decoder_self_att = MultiWaveletTransform(ich=d_model, L=L, base=base)\n",
    "        decoder_cross_att = MultiWaveletCross(in_channels=d_model,\n",
    "                                                out_channels=d_model,\n",
    "                                                seq_len_q=self.seq_len // 2 + self.pred_len,\n",
    "                                                seq_len_kv=self.seq_len,\n",
    "                                                modes=modes,\n",
    "                                                ich=d_model,\n",
    "                                                base=base,\n",
    "                                                activation=cross_activation)\n",
    "        # else:\n",
    "        #     encoder_self_att = FourierBlock(in_channels=d_model,\n",
    "        #                                     out_channels=d_model,\n",
    "        #                                     seq_len=self.seq_len,\n",
    "        #                                     modes=modes,\n",
    "        #                                     mode_select_method=mode_select)\n",
    "        #     decoder_self_att = FourierBlock(in_channels=d_model,\n",
    "        #                                     out_channels=d_model,\n",
    "        #                                     seq_len=self.seq_len//2+self.pred_len,\n",
    "        #                                     modes=modes,\n",
    "        #                                     mode_select_method=mode_select)\n",
    "        #     decoder_cross_att = FourierCrossAttention(in_channels=d_model,\n",
    "        #                                               out_channels=d_model,\n",
    "        #                                               seq_len_q=self.seq_len//2+self.pred_len,\n",
    "        #                                               seq_len_kv=self.seq_len,\n",
    "        #                                               modes=modes,\n",
    "        #                                               mode_select_method=mode_select)\n",
    "        # Encoder\n",
    "        enc_modes = int(min(modes, seq_len//2))\n",
    "        dec_modes = int(min(modes, (seq_len//2+pred_len)//2))\n",
    "        print('enc_modes: {}, dec_modes: {}'.format(enc_modes, dec_modes))\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AutoCorrelationLayer(\n",
    "                        encoder_self_att,\n",
    "                        d_model, n_heads, dtype=dtype),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    moving_avg=moving_avg,\n",
    "                    dropout=dropout,\n",
    "                    activation=activation,\n",
    "                    dtype=dtype\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=my_Layernorm(d_model, dtype=dtype)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AutoCorrelationLayer(\n",
    "                        decoder_self_att,\n",
    "                        d_model, n_heads, dtype=dtype),\n",
    "                    AutoCorrelationLayer(\n",
    "                        decoder_cross_att,\n",
    "                        d_model, n_heads, dtype=dtype),\n",
    "                    d_model,\n",
    "                    c_out,\n",
    "                    d_ff,\n",
    "                    moving_avg=moving_avg,\n",
    "                    dropout=dropout,\n",
    "                    activation=activation,\n",
    "                    dtype=dtype\n",
    "                )\n",
    "                for l in range(d_layers)\n",
    "            ],\n",
    "            norm_layer=my_Layernorm(d_model, dtype=dtype),\n",
    "            projection=nn.Linear(d_model, c_out, bias=True, dtype=dtype)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_enc,\n",
    "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
    "        # decomp init\n",
    "        mean = torch.mean(x_enc, dim=1).unsqueeze(1).repeat(1, self.pred_len, 1)\n",
    "        seasonal_init, trend_init = self.decomp(x_enc)\n",
    "        # decoder input\n",
    "        trend_init = torch.cat([trend_init[:, -self.label_len:, :], mean], dim=1)\n",
    "        seasonal_init = F.pad(seasonal_init[:, -self.label_len:, :], (0, 0, 0, self.pred_len))\n",
    "        # enc\n",
    "        enc_out = self.enc_embedding(x_enc)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
    "        # dec\n",
    "        dec_out = self.dec_embedding(seasonal_init)\n",
    "        seasonal_part, trend_part = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask,\n",
    "                                                 trend=trend_init)\n",
    "        # final\n",
    "        dec_out = trend_part + seasonal_part\n",
    "\n",
    "        if self.output_attention:\n",
    "            return dec_out[:, -self.pred_len:, :], attns\n",
    "        else:\n",
    "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
