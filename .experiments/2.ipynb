{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data file paths\n",
    "filepaths = [f\"/home/sbose/time-series-forecasting-federation/data/NREL{s}dataset.npz\" for s in ['CA','IL','NY']]\n",
    "\n",
    "# in this notebook, we will analyse the data files and try to see how we can make a custom data loader for the same.\n",
    "\n",
    "data_CA = np.load(filepaths[0])['data']\n",
    "data_IL = np.load(filepaths[1])['data']\n",
    "data_NY = np.load(filepaths[2])['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we write some basic code which allows the creation of a dataloader\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Union, List, Tuple\n",
    "from itertools import combinations\n",
    "\n",
    "class LFDataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data: np.array,\n",
    "        lookback: int,\n",
    "        lookahead: int,\n",
    "        idx_y: Union[List,Tuple],\n",
    "        idx_x: Union[List,Tuple],\n",
    "        idx_u: Union[List,Tuple],\n",
    "        idx_s: Union[List,Tuple],\n",
    "        dtype: torch.dtype = torch.float32\n",
    "    ):\n",
    "        \n",
    "        # sanity checks\n",
    "        assert len(data.shape) == 2, \"Incorrect number of dimensions in data.\"\n",
    "        assert len(idx_y) > 0, \"Cannot forecast indices of size 0\"\n",
    "        assert lookback > 0, \"Cannot have non-positive lookback!\"\n",
    "        assert lookahead > 0, \"Cannot have non-positive lookahead!\"\n",
    "        assert len(idx_y)+len(idx_x)+len(idx_u)+len(idx_s) == data.shape[1], \"Indices provided do not sum upto the input dimension.\"\n",
    "        assert all(not set(a) & set(b) for a, b in combinations([idx_y, idx_x, idx_u, idx_s], 2)), \"All indices are not mutually exclusive.\"\n",
    "        assert data.shape[0] >= lookback+lookahead, \"Data too short to generate even 1 sample!\"\n",
    "        \n",
    "        # save inputs\n",
    "        self.data, self.dtype = data, dtype\n",
    "        self.lookback, self.lookahead = lookback, lookahead\n",
    "        self.idx_y, self.idx_x, self.idx_u, self.idx_s = idx_y, idx_x, idx_u, idx_s\n",
    "        \n",
    "        # generate datas\n",
    "        self.records = []\n",
    "        for tidx in range(self.data.shape[0]-self.lookback-self.lookahead+1):\n",
    "            y_past = torch.tensor(self.data[tidx:tidx+lookback,idx_y], dtype=self.dtype)\n",
    "            x_past = torch.tensor(self.data[tidx:tidx+lookback,idx_x], dtype=self.dtype)\n",
    "            u_past = torch.tensor(self.data[tidx:tidx+lookback,idx_u], dtype=self.dtype)\n",
    "            s_past = torch.tensor(self.data[tidx:tidx+lookback,idx_s], dtype=self.dtype)\n",
    "            y_target = torch.tensor(self.data[tidx+lookback+lookahead-1,idx_y], dtype=self.dtype)\n",
    "            y_all_target = torch.tensor(self.data[tidx+lookback:tidx+lookback+lookahead,idx_y], dtype = dtype)\n",
    "            u_future = torch.tensor(self.data[tidx:tidx+lookback:tidx+lookback+lookahead,idx_u], dtype=self.dtype)\n",
    "            self.records.append((y_past,x_past,u_past,s_past,y_target,y_all_target,u_future))\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.records)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        record = self.records[idx]\n",
    "        y_past, x_past, u_past, s_past, y_target, y_all_target, u_future = record\n",
    "        inp = (y_past,x_past,u_past,s_past,u_future)\n",
    "        lab = (y_target, y_all_target)\n",
    "        \n",
    "        return inp, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now test out our dataset with california data\n",
    "\n",
    "# create dataset\n",
    "data_CA_truncated = data_CA[0,:,:]\n",
    "CA_dset = LFDataset(\n",
    "    data = data_CA_truncated,\n",
    "    lookback = 8,\n",
    "    lookahead = 4,\n",
    "    idx_y = [0],\n",
    "    idx_x = [3,4],\n",
    "    idx_u = [1,2],\n",
    "    idx_s = [5,6,7],\n",
    "    dtype = torch.float32\n",
    ")\n",
    "\n",
    "# load into dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "CA_dataloader = DataLoader(CA_dset, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cidx, (a,b) in enumerate(CA_dataloader):\n",
    "#     print(f\"On {cidx+1}th item of dataloader, type of a is {type(a)}, type of b is {type(b)}\")\n",
    "#     for idx,itm in enumerate(a):\n",
    "#         print(f\"Shape of {idx+1}th item in a is {itm.shape}.\")\n",
    "#     for idx,itm in enumerate(b):\n",
    "#         print(f\"Shape of {idx+1}th item in b is {itm.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of LSTM output is (32, 1).\n"
     ]
    }
   ],
   "source": [
    "# test out LSTM vanilla version\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "sys.path.insert(1,os.getcwd()+'/time-series-forecasting-federation')\n",
    "from models.LSTM.LSTMFCDecoder import LSTMFCDecoder\n",
    "\n",
    "model = LSTMFCDecoder(\n",
    "    input_size = 8,\n",
    "    hidden_size = 20,\n",
    "    num_layers = 2,\n",
    "    y_size = 1,\n",
    "    fcnn_sizes = (160,10,10,1),\n",
    "    activation = nn.ReLU,\n",
    "    lookback = 8,\n",
    "    lookahead = 4,\n",
    "    dtype = torch.float32\n",
    ")\n",
    "\n",
    "# evaluate the model\n",
    "for a,b in CA_dataloader:\n",
    "    w = model(a)\n",
    "    print(f\"Shape of LSTM output is {tuple(w.shape)}.\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
